{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# CNN"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.046566Z", "start_time": "2020-08-11T08:05:54.171499Z"}}, "outputs": [], "source": ["import torch\n", "import torch.nn.functional as F\n", "\n", "from torch import nn\n", "from torchsummary import summary"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1 Basic"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2 BatchNorm\n", "BatchNorm\u7684\u4ecb\u7ecd\u5177\u4f53\u53c2\u8003[\u52a8\u624b\u6df1\u5ea6\u5b66\u4e60](https://zh.d2l.ai/chapter_convolutional-neural-networks/batch-norm.html)\u3002\u5bf9\u4e8eFC\u5c42\u8f93\u51fa\u5728\u6bcf\u4e2a\u901a\u9053\u4e0a\u8fdb\u884cBS(batch size)\u7ea7\u522b\u7684\u5f52\u4e00\u5316\uff1b\u5bf9\u4e8eConv\u5c42\u8f93\u51fa\u5728\u6bcf\u4e2a\u901a\u9053\u4e0aHxWxBS\u7ea7\u522b\u7684\u5f52\u4e00\u5316\u3002\n", "\n", "BatchNorm\u867d\u7136\u597d\u7528\uff0c\u4f46\u662f\u4e5f\u6709\u4e00\u4e9b\u95ee\u9898\uff08\u8be6\u89c1[Devils in BatchNorm](https://www.techbeat.net/talks/MTU5NzEyNzg2MjU2MC0yOTktNzUzMjI=)\uff09\uff0c\u4f8b\u5982\u4e0d\u4e00\u81f4\u6027\uff08inconsistency\uff09\u95ee\u9898\uff1a\n", "1. \u4f7f\u7528\u4e86[\u6307\u6570\u79fb\u52a8\u5e73\u5747](https://zhuanlan.zhihu.com/p/68748778)\u4f1a\u8ba9\u5b66\u4e60\u7684\u53c2\u6570\u66f4\u52a0\u9002\u5e94\u6700\u65b0\u8bad\u7ec3\u6279\u6b21\u7684\u6837\u672c\n", "2. \u8bad\u7ec3\u96c6\u5f97\u5230\u7684batchnorm\u53c2\u6570\u4e0d\u4e00\u5b9a\u9002\u5408\u6d4b\u8bd5\u96c6\n", "\n", "\u7b2c1\u4e2a\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u53ef\u4ee5\u4f7f\u7528Precise BatchNorm\uff0c\u4f8b\u5982\u6682\u505c\u66f4\u65b0\u7f51\u7edc\u53c2\u6570\uff0c\u53ea\u66f4\u65b0BatchNorm\u5c42\u7684\u53c2\u6570\u3002"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.056749Z", "start_time": "2020-08-11T08:05:55.049796Z"}}, "outputs": [], "source": ["# target output size of 10x7\n", "m = nn.AdaptiveMaxPool2d((None, 7))\n", "input = torch.randn(1, 64, 10, 9)\n", "output = m(input)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3 Paper"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3.1 SENet\n", "- \u53c2\u8003\uff1a[[\u8bba\u6587\u7b14\u8bb0]-SENet\u548cSKNet(\u9644\u4ee3\u7801)](https://zhuanlan.zhihu.com/p/76033612)\n", "- Pytorch\u4ee3\u7801\uff1ahttps://github.com/moskomule/senet.pytorch\n", "\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/6sfp5yrczet76xl5qitd9cv4/image.png)\n", "\n", "\u4e00\u5171\u6709\u4e09\u6b65\uff0c\u5206\u522b\u662fSqueeze\uff0cExcitation\u548cFscale\u3002\u4ee3\u7801\u4e2d\u7684`r`\u662f\u4e00\u4e2a\u7f29\u653e\u53c2\u6570\uff0c\u9ed8\u8ba416\uff0c\u6587\u4e2d\u8bf4\u5f15\u5165\u8fd9\u4e2a\u53c2\u6570\u662f\u4e3a\u4e86\u51cf\u5c11`channel`\u4e2a\u6570\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u91cf\u3002"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.069689Z", "start_time": "2020-08-11T08:05:55.060245Z"}}, "outputs": [], "source": ["class SEBlock(nn.Module):\n", "    def __init__(self, channel, r=16):\n", "        super().__init__()\n", "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n", "        self.fc = nn.Sequential(\n", "            nn.Linear(channel, channel//r, bias=False),\n", "            nn.ReLU(inplace=True),\n", "            nn.Linear(channel//r, channel, bias=False),\n", "            nn.Sigmoid(),\n", "        )\n", "\n", "    def forward(self, x):\n", "        b, c , _, _ = x.size()\n", "        # Squeeze\n", "        y = self.avg_pool(x).view(b, c)\n", "        # Excitation\n", "        y = self.fc(y).view(b, c, 1, 1)\n", "        # Fscale\n", "        y = torch.mul(x, y)\n", "        return y"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.099798Z", "start_time": "2020-08-11T08:05:55.073140Z"}}, "outputs": [{"data": {"text/plain": ["torch.Size([1, 128, 28, 28])"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["x = torch.rand(1, 128, 28, 28)\n", "out = SEBlock(128)(x)\n", "\n", "out.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u53ef\u4ee5\u770b\u5230`SEBlock`\u5e76\u6ca1\u6709\u6539\u53d8`x.shape`\uff0c\u53ea\u662f\u7ed9\u6bcf\u4e2a\u901a\u9053\u6839\u636e\u8ba1\u7b97\u7684\u6743\u91cd\u91cd\u65b0\u8d4b\u503c\u3002\n", "\n", "`SEBlock`\u5f88\u5bb9\u6613\u96c6\u6210\u5230\u73b0\u6709\u7684\u6a21\u5757\u4e2d\uff0c\u4f8b\u5982\u5bf9ResNet\u6765\u8bf4\u53ea\u9700\u8981\u5bf9`Residual`\u52a0\u4e00\u6b65`SEBlock`\u5373\u53ef\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/jk0x9zla6pe93few53nz7vow/image.png)\n", "\n", "\u96c6\u6210\u7684SE-ResNet\u53ef\u4ee5\u53c2\u8003[github](https://github.com/moskomule/senet.pytorch/blob/master/senet/se_resnet.py#L11)\uff0c\u90e8\u5206\u4ee3\u7801\u5982\u4e0b\u6240\u793a\u3002\u6ce8\u610f\u8fd9\u4e2a\u4ed3\u5e93\u4e2d\u547d\u540d\u7684\u662f`SELayer`\u800c\u4e0d\u662f`SEBlock`\u3002"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.158383Z", "start_time": "2020-08-11T08:05:55.103005Z"}, "code_folding": []}, "outputs": [], "source": ["%%script true\n", "from torchvision.models import ResNet\n", "\n", "\n", "def se_resnet34(num_classes=1_000):\n", "    \"\"\"Constructs a ResNet-34 model.\n", "    Args:\n", "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n", "    \"\"\"\n", "    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n", "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n", "    return model\n", "\n", "\n", "def se_resnet50(num_classes=1_000, pretrained=False):\n", "    \"\"\"Constructs a ResNet-50 model.\n", "    Args:\n", "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n", "    \"\"\"\n", "    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\n", "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n", "    if pretrained:\n", "        model.load_state_dict(load_state_dict_from_url(\n", "            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\n", "    return model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3.2 SKNet\n", "- \u53c2\u8003\uff1a[[\u8bba\u6587\u7b14\u8bb0]-SENet\u548cSKNet(\u9644\u4ee3\u7801)](https://zhuanlan.zhihu.com/p/76033612)\n", "\n", "SKNet\u7684\u6838\u5fc3\u5c31\u662fSelective Kernel Convolution\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/j8m6bvndtwx4zgq6m9sy73tm/image.png)\n", "\n", "Selective Kernel Convolution\u4e3b\u8981\u6709\u4e09\u6b65\uff1a\n", "1. **Split**\uff1a\u7528\u4e86\u4e24\u7ec4\u4e0d\u540c\u5927\u5c0f\u7684Kernel\u5bf9$X$\u5206\u522b\u505a\u5377\u79ef\u8fd0\u7b97\uff0c\u5f97\u5230\u4e24\u4e2a\u76f8\u540cshape\u7684\u8f93\u51fa$\\widetilde{\\mathbf{U}}$\u548c$\\widehat{\\mathbf{U}}$\u3002\n", "\n", "2. **Fuse**\uff1a\u5c06$\\widetilde{\\mathbf{U}}$\u548c$\\widehat{\\mathbf{U}}$\u76f8\u52a0\u5f97\u5230$\\mathbf{U}$\uff0c\u7136\u540e\u7c7b\u4f3cSENet\u5bf9$\\mathbf{U}$\u8ba1\u7b97\u901a\u9053\u4e4b\u95f4\u7684\u6743\u91cd$a,b$\u3002\u4f46\u662f\u4e0d\u540c\u4e8eSENet\u8ba1\u7b97\u4e00\u7ec4\u901a\u9053\u4e4b\u95f4\u7684\u6743\u91cd\uff0c\u5373\u4e00\u6b21softmax\u8fd0\u7b97\uff1b\u800cSKNet\u8ba1\u7b97\u6bcf\u4e2a\u901a\u9053\u5728\u4e24\u4e2a\u5206\u652f\u4e0a\u7684\u6743\u91cd\uff0c\u5171channel\u6b21softmax\u8fd0\u7b97\uff0c\u4e5f\u5c31\u662f$a,b$\u6bcf\u4e2a\u76f8\u540c\u4f4d\u7f6e\u4e0a\u7684\u503c\u52a0\u8d77\u6765\u4e3a1\u3002\n", "\n", "3. **Select**\uff1a\u6839\u636e\u8ba1\u7b97$a,b$\u5bf9$\\widetilde{\\mathbf{U}}$\u548c$\\widehat{\\mathbf{U}}$\u505a\u52a0\u6743\u6c42\u548c\uff0c\u5f97\u5230$\\mathbf{V}$\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u4e0b\u9762\u7684\u4ee3\u7801\u5b9e\u73b0\u4e86Selective Kernel Convolution\u3002\u6ce8\u610f\u51e0\u70b9\uff1a\n", "1. `M`\u5bf9\u5e94\u5206\u652f\u6570\n", "2. `reduction`\u5bf9\u5e94SENet\u4e2d\u7684r\uff0c\u662f\u4e00\u4e2a\u7f29\u653e\u53c2\u6570\uff0c\u76ee\u7684\u51cf\u5c11channel\u4e2a\u6570\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u91cf\n", "3. \u8bba\u6587\u4e2d\u8bf4\u53ef\u4ee5\u7528dilated\u7684`conv3x3`\u4ee3\u66ff`conv5x5`\uff0c\u5bf9\u5e94\u4ee3\u7801`dilation=1+i`\n", "4. `forward`\u4e2d\u7684`feats`\u5bf9\u5e94$\\mathbf{U}$\uff0cshape\u548c`x`\u76f8\u540c"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.173237Z", "start_time": "2020-08-11T08:05:55.161551Z"}}, "outputs": [], "source": ["class SKConv(nn.Module):\n", "    def __init__(self, channels, stride=1, M=2, reduction=4):\n", "        super().__init__()\n", "        self.conv1 = nn.ModuleList([])\n", "        for i in range(M):\n", "            self.conv1.append(nn.Sequential(\n", "                nn.Conv2d(channels, channels, 3, stride,\n", "                          padding=1+i, dilation=1+i, bias=False),\n", "                nn.BatchNorm2d(channels),\n", "                nn.ReLU()\n", "            ))\n", "        self.att = nn.Sequential(\n", "            nn.AdaptiveAvgPool2d(1),\n", "            nn.Conv2d(channels, channels//reduction, 1),\n", "            nn.ReLU(),\n", "            nn.Conv2d(channels//reduction, channels * M, 1)\n", "        )\n", "\n", "    def forward(self, x):\n", "        splited = [conv(x) for conv in self.conv1]\n", "        feats = sum(splited)  \n", "        att = self.att(feats) # shape = (batch num, (channels*M), 1, 1)\n", "        # shape = (batch num, M, channels)\n", "        att = att.view(x.size(0), len(self.conv1), x.size(1)) \n", "        att = F.softmax(att, dim=1)\n", "        att = att.view(x.size(0), -1, 1, 1)\n", "        att = torch.split(att, x.size(1), dim=1)\n", "\n", "        return sum([a * s for a, s in zip(att, splited)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6d4b\u8bd5\u4e00\u4e0b$14\\times 14$\u5757\uff08\u89c1\u4e0b\u9762\u7b2c\u4e8c\u4e2a\u56fe\uff09\u4e2d\u7684`SKConv`\u3002\u6ce8\u610f\u5982\u679c\u4e0d\u662f\u5757\u4e2d\u7b2c\u4e00\u6b21\u5377\u79ef\u8fd0\u7b97\uff08\u5373\u8f93\u5165\u4e0d\u662f$28\\times 28$\u7684\u8f93\u51fa\uff09\uff0c\u662f\u4e0d\u9700\u8981\u6539\u53d8feature maps\u7684\u5927\u5c0f\uff0c\u4f7f\u7528\u9ed8\u8ba4`stride=1`\u3002"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.908682Z", "start_time": "2020-08-11T08:05:55.179090Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([2, 1024, 14, 14])\n", "loss value : 0.4172205328941345\n"]}], "source": ["x = torch.rand(2, 1024, 14, 14)\n", "skconv = SKConv(1024)\n", "out = skconv(x)\n", "print('out shape : {}'.format(out.shape))\n", "\n", "# \u6d4b\u8bd5backward()\u548closs\n", "criterion = nn.L1Loss()\n", "loss = criterion(out, x)\n", "loss.backward()\n", "print('loss value : {}'.format(loss))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6709\u4e86`SKConv`\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6784\u5efa\u57fa\u4e8eSKNet\u7684ResNet\u4e86\uff0c\u4f8b\u5982SKNet-50\uff0c\u53ea\u9700\u8981\u66ff\u6362ResNet\u6a21\u5757\u4e2d\u7684$3\\times 3$\u5377\u79ef\u3002ResNet\u6a21\u5757\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5de6\u8fb9\u662f\u666e\u901a\u7684ResNet\u6a21\u5757\uff0c\u53f3\u8fb9\u662fbottlenecck\u7ed3\u6784\u7684ResNet\u6a21\u5757\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/geba8sxfed73kwumnyrdwiy7/image.png)\n", "\n", "\u5b8c\u6574\u7684SKNet\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5728max pool\u4e4b\u540e\uff0c\u6bcf\u4e2ablock\u4f1a\u91cd\u590d\u4e00\u5b9a\u7684\u6b21\u6570\uff083\uff0c4\uff0c6\uff0c3\uff09\uff0c\u8fd9\u4e9bblock\u7b2c\u4e00\u6b21\u65f6\u5019\u90fd\u9700\u8981\u5c06feature maps\u51cf\u534a\uff0c\u6b64\u65f6\u8f93\u5165\u7684\u901a\u9053\u6570\u662f\u8f93\u51fa\u7684\u4e00\u534a\u3002\u4f8b\u5982$56\\times 56$\u4e2d\u6700\u540e\u4e00\u6b21\u8f93\u51fa\u7684\u901a\u9053\u6570\u4e3a256\uff0c\u5373$28\\times 28$\u7684\u8f93\u5165\uff0c\u800c$28\\times 28$\u7684\u8f93\u51fa\u4e3a512\u3002\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/f7cgwxi5o8xmvyry1oysr56h/image.png)\n", "\n", "\u4ee3\u7801\u4e2d\u4f7f\u7528\u4e86`in_channels == out_channels`\u6765\u5224\u65ad\u662f\u5426\u9700\u8981\u5bf9feature maps\u7684\u5927\u5c0f\u51cf\u534a\uff1a"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:55.925409Z", "start_time": "2020-08-11T08:05:55.912200Z"}}, "outputs": [], "source": ["from torch.nn.quantized import FloatFunctional\n", "\n", "\n", "class SKUnit(nn.Module):\n", "    def __init__(self, in_channels, out_channels):\n", "        super().__init__()\n", "\n", "        if in_channels == out_channels:\n", "            mid_channels = in_channels // 2\n", "            stride = 1\n", "            self.shortcut = nn.Sequential()\n", "        else:\n", "            mid_channels = in_channels\n", "            stride = 2\n", "            self.shortcut = nn.Sequential(\n", "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n", "                nn.BatchNorm2d(out_channels))\n", "            \n", "        self.conv1 = nn.Sequential(\n", "            nn.Conv2d(in_channels, mid_channels, 1, bias=False),\n", "            nn.BatchNorm2d(mid_channels),\n", "            nn.ReLU(inplace=True)\n", "        )\n", "        self.conv2 = nn.Sequential(\n", "            SKConv(mid_channels, stride),\n", "            nn.BatchNorm2d(mid_channels),\n", "            nn.ReLU(inplace=True)\n", "        )\n", "        self.conv3 = nn.Sequential(\n", "            nn.Conv2d(mid_channels, out_channels, 1, bias=False),\n", "            nn.BatchNorm2d(out_channels)\n", "        )\n", "\n", "        self.relu = FloatFunctional()\n", "\n", "    def forward(self, x):\n", "        out = self.conv1(x)\n", "        out = self.conv2(out)\n", "        out = self.conv3(out)\n", "        x = self.shortcut(x)\n", "        return self.relu.add_relu(x, out)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6d4b\u8bd5\u4e0d\u9700\u8981\u51cf\u534a\u7684`SKUnit`\uff1a"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:56.002764Z", "start_time": "2020-08-11T08:05:55.927877Z"}}, "outputs": [{"data": {"text/plain": ["torch.Size([8, 64, 32, 32])"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["x = torch.rand(8, 64, 32, 32)\n", "out = SKUnit(64, 64)(x)\n", "\n", "out.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6d4b\u8bd5\u9700\u8981\u51cf\u534a\u7684SKUnit\uff1a"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:56.090975Z", "start_time": "2020-08-11T08:05:56.008952Z"}}, "outputs": [{"data": {"text/plain": ["torch.Size([8, 128, 16, 16])"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["out = SKUnit(64, 128)(x)\n", "\n", "out.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3.3 ResNeXt\n", "- [ResNeXt\u7684\u5206\u7c7b\u6548\u679c\u4e3a\u4ec0\u4e48\u6bd4Resnet\u597d?](https://www.zhihu.com/question/323424817)\n", "- [\u85b0\u98ce\u8bfb\u8bba\u6587\uff1aResNeXt \u6df1\u5165\u89e3\u8bfb\u4e0e\u6a21\u578b\u5b9e\u73b0](https://zhuanlan.zhihu.com/p/78019001)\n", "\n", "\u795e\u7ecf\u7f51\u7edc\u6709\u4e24\u4e2a\u91cd\u8981\u7684\u53c2\u6570\uff0c\u6df1\u5ea6\u548c\u5bbd\u5ea6\uff08\u8fd9\u91cc\u6307\u7684\u662f\u901a\u9053\u6570\uff1athe number of channels in a layer\uff09\uff0c\u7ecf\u8fc7ResNet\u7b49\u6587\u7ae0\u6539\u8fdb\u540e\uff0c\u8fd9\u4e24\u4e2a\u53c2\u6570\u5bf9\u76ee\u524d\u7684\u7f51\u7edc\u7684\u63d0\u5347\u6548\u679c\u4e0d\u662f\u5f88\u660e\u663e\u4e86\uff0c\u5927\u5bb6\u5f00\u59cb\u5bf9\u5404\u79cd\u8d85\u53c2\u4e0b\u624b\uff0c\u8fd9\u6837\u5f88\u5bb9\u6613\u5bfc\u81f4\u67d0\u4e00\u6570\u636e\u96c6\u78b0\u5de7\u9002\u5408\u4e00\u4e2a\u201c\u4e71\u8c03\u201d\u7684\u8d85\u53c2\uff0c\u4f7f\u7f51\u7edc\u4e27\u5931\u4e86\u6cdb\u5316\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u53c2\u6570cardinality\uff0c\u5982\u4e0b\u56fe\u53f3\u8fb9\u7f51\u7edc\u4e2d\u7684\u201ctotal 32 paths\u201d\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u5bf9\u56fe\u4e2d\u5de6\u8fb9\u76843x3 conv\u505a\u5206\u7ec4\u5377\u79ef\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/4i1l4zpoi5h4f197on71hcs2/image.png)\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/g0ttoq6klzia3adzxtz81prs/image.png)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["\u4f5c\u8005\u8fd9\u4e48\u505a\u7684\u539f\u56e0\u662f\u53d7\u5230Inception\u7ed3\u6784\u548cAlexNet\u5206\u7ec4\u5377\u79ef\u542f\u53d1\uff0c\u8ba4\u4e3a**split-transform-merge\u7ed3\u6784\u80fd\u8fbe\u5230\u5927\u578b\u5bc6\u96c6\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b**\uff0c\u800c\u8ba1\u7b97\u91cf\u5374\u8981\u5c0f\u5f88\u591a\u3002\n", "\n", "> [ResNeXt\u7684\u5206\u7c7b\u6548\u679c\u4e3a\u4ec0\u4e48\u6bd4Resnet\u597d?](https://www.zhihu.com/question/323424817/answer/1078704765) \u4e00\u4e2a\u7b54\u6848\u8ba4\u4e3a\u591a\u4e2acardinality\u548cNLP\u4e2d\u7684multi-head attention\u662f\u4e00\u4e2a\u601d\u8def\u3002\u6bcf\u7ec4\u662f\u4e0d\u540c\u7684subspace\uff0c\u5c31\u80fd\u5b66\u5230\u66f4diverse\u7684\u8868\u793a\u3002\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/b5cahsk10t89licwxt5s8ek1/image.png)\n", "\n", "\u63a5\u7740\u4e3a\u4e86\u7b80\u5316\u8ba1\u7b97\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u4e0a\u56fe\u4e2d3\u4e2ablock\u662f\u7b49\u4ef7\u7684\uff0c\u4e8e\u662f**\u8f93\u5165\u548c\u8f93\u51fa\u5c31\u7b80\u5316\u6210\u4e86\u4e00\u6b211x1\u7684\u5377\u79ef**\uff0c\u800c\u4e0d\u662f\u539f\u6765cardinality\uff08\u4e0a\u56fe\u4e2d\u4e3a32\uff09\u6b21\u3002\u5bf9\u6bd4\u539f\u6765\u7684ResNet\u7ed3\u6784\uff08\u7b2c\u4e00\u5f20\u56fe\u5de6\uff09\uff0cResNeXt\u4e2d\u7684\u901a\u9053\u603b\u6570\u53cd\u800c\u589e\u591a\u4e86\uff08\u4ece64\u53d8\u6210\u4e86128\uff09\uff0c\u8fd9\u6837\u5176\u5b9e\u4e5f\u662f\u589e\u52a0\u4e86\u6a21\u578b\u7684\u80fd\u529b\uff0c**\u4f46\u662f\u91cd\u70b9\u662f\u51e0\u4e4e\u6ca1\u6709\u589e\u52a0\u4efb\u4f55\u7684\u8ba1\u7b97\u91cf\u548c\u53c2\u6570\u91cf\uff01\uff01\uff01\uff0c\u539f\u7406\u7c7b\u4f3cDepthwise Conv**\uff0c\u8ba1\u7b97\u91cf\u548c\u53c2\u6570\u91cf\u53c2\u89c1\u4e0b\u56fe\u6700\u540e\u4e00\u884c\u3002\n", "\n", "\u4ee3\u7801\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5bf9ResNet\u7684\u4ee3\u7801\u5fae\u8c03\uff1a\u4e00\u662f\u8f93\u5165\u7684\u901a\u9053\u6570\uff1b\u4e8c\u662f\u5c06\u4e2d\u95f4\u7684conv3x3\u53d8\u6210\u5206\u7ec4\u5377\u79ef\uff0c\u53ea\u8981\u4f20\u5165`groups=cardinality`\u53c2\u6570\u5373\u53ef\uff1a"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:56.112220Z", "start_time": "2020-08-11T08:05:56.093683Z"}}, "outputs": [], "source": ["class Block(nn.Module):\n", "    '''Grouped convolution block.'''\n", "    expansion = 2\n", "\n", "    def __init__(self, in_channels, gw, cardinality=32, stride=1):\n", "        \"\"\"\n", "        @gw, group width\n", "        \"\"\"\n", "        super().__init__()\n", "        \n", "        out_channels = gw * self.expansion\n", "        \n", "        self.conv1 = nn.Sequential(\n", "            nn.Conv2d(in_channels, gw, kernel_size=1, bias=False),\n", "            nn.BatchNorm2d(gw),\n", "            nn.ReLU()\n", "        )\n", "        self.conv2 = nn.Sequential(\n", "            nn.Conv2d(gw, gw, kernel_size=3, stride=stride,\n", "                      padding=1, groups=cardinality, bias=False),\n", "            nn.BatchNorm2d(gw),\n", "            nn.ReLU()\n", "        )\n", "        self.conv3 = nn.Sequential(\n", "            nn.Conv2d(gw, out_channels, kernel_size=1, bias=False),\n", "            nn.BatchNorm2d(out_channels),\n", "            nn.ReLU()\n", "        )\n", "\n", "        if (stride != 1) or (in_channels != out_channels):\n", "            self.shortcut = nn.Sequential(\n", "                nn.Conv2d(in_channels, out_channels,\n", "                          kernel_size=1, stride=stride),\n", "                nn.BatchNorm2d(out_channels))\n", "        else:\n", "            self.shortcut = nn.Sequential()\n", "\n", "    def forward(self, x):\n", "        out = self.conv1(x)\n", "        out = self.conv2(out)\n", "        out = self.conv3(out)\n", "        out += self.shortcut(x)\n", "        out = F.relu(out)\n", "        return out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6d4b\u8bd5\u4e0b\u56fe\u4e2dconv4\u7b2c\u4e00\u6b21\u4e4b\u540e\u7684\u8f93\u5165\uff1a"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:56.204924Z", "start_time": "2020-08-11T08:05:56.115568Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([2, 1024, 14, 14])\n"]}], "source": ["x = torch.rand(2, 1024, 14, 14)\n", "out = Block(1024, 512)(x)\n", "\n", "print('out shape : {}'.format(out.shape))"]}, {"cell_type": "markdown", "metadata": {"ExecuteTime": {"end_time": "2020-08-06T15:11:59.990419Z", "start_time": "2020-08-06T15:11:59.985027Z"}}, "source": ["\u6d4b\u8bd5\u4e0b\u56fe\u4e2dconv4\u7b2c\u4e00\u6b21\u8f93\u5165\uff0c\u5373conv3\u7684\u8f93\u51fa\uff1a"]}, {"cell_type": "code", "execution_count": 13, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:56.341743Z", "start_time": "2020-08-11T08:05:56.209034Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([2, 1024, 14, 14])\n"]}], "source": ["x = torch.rand(2, 512, 28, 28)\n", "out = Block(512, 512, stride=2)(x)\n", "\n", "print('out shape : {}'.format(out.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![](http://static.zybuluo.com/AustinMxnet/a8sd9f5m8g0vz762s07iqxco/image.png)\n", "\n", "\u6709\u4e86\u57fa\u7840\u7684`Block`\u5c31\u53ef\u4ee5\u6784\u5efa\u5b8c\u6574\u7684`ResNeXt`\u4e86\uff0c\u4f8b\u5982\u4e0a\u56fe\u5bf9\u6bd4\u4e86`ResNet-50`\u548c`ResNeXt-50`\u3002\u4ee3\u7801\u7c7b\u4f3c[ResNet](https://github.com/pytorch/vision/blob/3942b192e33dd79b6d9770149371bd58a483d47b/torchvision/models/resnet.py#L101)\uff0c\u63d0\u6362\u4e3a\u4e0a\u9762\u7684`Block`\u5e76\u65b0\u589e`cardinality`\u53c2\u6570\uff1a"]}, {"cell_type": "code", "execution_count": 14, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:56.368477Z", "start_time": "2020-08-11T08:05:56.344925Z"}}, "outputs": [], "source": ["class ResNeXt(nn.Module):\n", "    def __init__(self, block, layers, cardinality, num_classes=1000):\n", "        super(ResNeXt, self).__init__()\n", "        self.inplanes = 64\n", "        self.cardinality = cardinality\n", "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,\n", "                               stride=2, padding=3, bias=False)\n", "        self.bn1 = nn.BatchNorm2d(64)\n", "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n", "\n", "        self.layer1 = self._make_layer(block, 128, layers[0],\n", "                                       in_channels=64)\n", "        self.layer2 = self._make_layer(block, 256,  layers[1])\n", "        self.layer3 = self._make_layer(block, 512,  layers[2])\n", "        self.layer4 = self._make_layer(block, 1024, layers[3])\n", "\n", "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n", "        self.fc = nn.Linear(1024 * block.expansion, num_classes)\n", "\n", "    def _make_layer(self, block, group_width, num_blocks, in_channels=None):\n", "        layers = []\n", "\n", "        if in_channels == None:\n", "            in_channels = group_width\n", "        layers.append(block(in_channels, group_width, self.cardinality, 2))\n", "\n", "        inchannels = group_width * block.expansion\n", "        for _ in range(1, num_blocks):\n", "            layers.append(\n", "                block(inchannels, group_width, self.cardinality, 1))\n", "        return nn.Sequential(*layers)\n", "\n", "    def forward(self, x):\n", "        out = F.relu(self.bn1(self.conv1(x)))\n", "        out = self.maxpool(out)\n", "\n", "        out = self.layer1(out)\n", "        out = self.layer2(out)\n", "        out = self.layer3(out)\n", "        out = self.layer4(out)\n", "\n", "        out = self.avgpool(out)\n", "        out = out.view(out.size(0), -1)\n", "        out = self.fc(out)\n", "\n", "        return out\n", "\n", "\n", "def ResNeXt50_32x4d():\n", "    return ResNeXt(Block, layers=[3, 4, 6, 3], cardinality=32)"]}, {"cell_type": "code", "execution_count": 15, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.228478Z", "start_time": "2020-08-11T08:05:56.376098Z"}, "scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([2, 1000])\n"]}], "source": ["x = torch.rand(2, 3, 224, 224)\n", "out = ResNeXt50_32x4d()(x)\n", "\n", "print('out shape : {}'.format(out.shape))\n", "#summary(ResNeXt50_32x4d(), (3, 224, 224))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3.4 ResNeSt\n", "- \u4f5c\u8005\u89c6\u9891\u8bb2\u89e3\uff1a[\u5f20\u822a-ResNeSt\uff1a\u62c6\u5206\u6ce8\u610f\u529b\u7f51\u7edc](https://www.bilibili.com/video/BV1PV411k7ch)\n", "\n", "\u867d\u7136\u8bba\u6587\u4e2d\u7ed9\u7684\u56fe\u6bd4\u8f83\u4e86SENet\u548cSKNet\uff0c\u4f46\u662fResNeSt\u4e3b\u8981\u7ed3\u5408\u4e86SKNet\u7684\u5206\u652f\u95f4\u901a\u9053attention\uff0c\u548cResNeXt\u591a\u5206\u652f\u7684\u7279\u70b9\u3002\u5728ResNeSt\u63d0\u51facardinality\u7684\u57fa\u7840\u4e0a\uff0c\u5728\u6bcf\u4e2acardinality\u7ef4\u5ea6\u4e2d\u53c8\u65b0\u589e\u4e86radix\u53c2\u6570\uff0c\u4e5f\u5c31\u662f\u5206\u652f\u4e2d\u7684\u5206\u652f\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/c4tn4s3wfk9m1f70o871zero/image.png)\n", "\n", "\u9996\u5148\u770b\u4e0b\u5355\u72eccardinality\u6a21\u5757\u7684\u5904\u7406\uff0c\u5148\u7ecf\u8fc71x1\u5377\u79ef\u7f29\u5c0f\u901a\u9053\uff0c\u7136\u540e\u7ecf\u8fc73x3\u5377\u79ef\u63d0\u53d6\u7279\u5f81\uff0c\u8fd9\u548c\u6807\u51c6\u7684ResNet\u6ca1\u533a\u522b\uff08\u9664\u4e86\u662fradix\u4e2a\u5206\u652f\uff09\u3002\u4e0b\u9762\u5c31\u662fResNeSt\u4e2d\u91cd\u70b9**Split Attention**\uff1a"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![](http://static.zybuluo.com/AustinMxnet/z6bbl89fjw9k7wpgm068z6nz/image.png)\n", "\n", "\u56fe\u4e2d$r$\u4e2a$h \\times w \\times c'$\u7684\u8f93\u5165\u7ecf\u8fc7Global Average Pooling\u548c2\u4e2aFC\u5c42\u540e\uff0c\u5f97\u5230$r$\uff08radix\uff09\u4e2a`Dense c`\uff0c\u7136\u540e\u5728$c$\uff08channel\uff09\u7ef4\u5ea6\u4e0a\u505asoftmax\uff0c\u5f97\u5230$r \\times c$\u7684\u6743\u91cd\u56fe\uff0c\u6743\u91cd\u56fe\u7684\u7b2c$i$\u5217\u5bf9\u5e94\u7b2c$i$\u4e2achannel\u7684$r$\u4e2a\u6743\u91cd\u5206\u5e03\uff0c\u4e0b\u9762\u7684\u4ee3\u7801\u7701\u7565\u4e86GAP\u548cFC\uff1a"]}, {"cell_type": "code", "execution_count": 16, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.247183Z", "start_time": "2020-08-11T08:05:57.231582Z"}}, "outputs": [{"data": {"text/plain": ["tensor([[0.3744, 0.5641, 0.6910],\n", "        [0.6256, 0.4359, 0.3090]])"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["r = 2\n", "c = 3\n", "x = torch.rand(r, c)\n", "xs = F.softmax(x, dim=0)\n", "xs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u7ed3\u679c\u6743\u91cd`xs`\u4e2d\u6bcf\u4e00\u5217\u6709$r=2$\u4e2a\u6743\u91cd\uff08\u6bcf\u4e00\u5217\u548c\u4e3a1\uff09\u3002\n", "\n", "**\u8fd9\u6837\u867d\u7136\u80fd\u6c42\u5f97cardinality\u4e2a\u5927\u5206\u652f\u7684\u8f93\u51fa\uff0c\u4f46\u662f\u8981\u8ba1\u7b97cardinality\u6b21**\u3002\u5728\u9644\u5f55\u4e2d\uff0c\u4f5c\u8005\u5c06$\\text{radix} \\times \\text{cardinality}$\u7b49\u4ef7\u53d8\u6362\u4e3a$\\text{cardinality} \\times \\text{radix}$\uff0c\u8fd9\u6837\u53ea\u9700\u8ba1\u7b97\u4e00\u6b21\u5c31\u53ef\u4ee5\u5f97\u5230$\\text{radix} \\times \\text{cardinality} \\times c$\u7684softmax\u6743\u91cd\u56fe\uff1a"]}, {"cell_type": "code", "execution_count": 17, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.273833Z", "start_time": "2020-08-11T08:05:57.259189Z"}}, "outputs": [{"data": {"text/plain": ["tensor([[[0.3929, 0.5925, 0.6940],\n", "         [0.5490, 0.5550, 0.4919],\n", "         [0.4783, 0.5026, 0.4754],\n", "         [0.5935, 0.5793, 0.6971]],\n", "\n", "        [[0.6071, 0.4075, 0.3060],\n", "         [0.4510, 0.4450, 0.5081],\n", "         [0.5217, 0.4974, 0.5246],\n", "         [0.4065, 0.4207, 0.3029]]])"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["r = 2\n", "cardinality = 4\n", "c = 3\n", "x_gap = torch.rand(cardinality, r, c) # after global average pooling\n", "xs = x_gap.transpose(0, 1)\n", "xs = F.softmax(xs, dim=0)\n", "xs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6ce8\u610f\u867d\u7136\u8f93\u5165\u7684shape\u4e3a$\\text{cardinality} \\times r \\times c$\uff0c\u4f46\u662f\u7ecf\u8fc7`transpose(0, 1)`\u540e\u5c31\u5bf9\u8c03\u4e86$\\text{cardinality}$\u548c$r$\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff08k=cardinality\uff09\uff0c\u82e5\u5c06$(h,w,c)$\u5206\u4e3a$(k, r, h, w, c')$\uff0c\u5e76\u6309\u7167\u76f8\u540c$r$\u7684$k \\times (h,w,c')$\u653e\u5728\u4e00\u8d77\uff0c\u53ea\u9700\u8981\u7528\u4e00\u4e2agroup conv\u751f\u6210\uff1a`nn.Conv2d(c, c'*radix, groups=cardinality*radix)`\u3002\n", "\n", "> \u56fe\u4e2d\u4e00\u5171\u6709$\\text{cardinality}=k$\u7ec4\uff0c\u6bcf\u7ec4\u6709$\\text{radix}=r$\u4e2a\u5206\u652f\uff0c\u6bcf\u4e2a\u5206\u652f\u901a\u9053\u6570\u4e3a$c'/k$\u3002\u6240\u4ee5\u5f53`Conv2d`\u7684\u53c2\u6570`out_channel=c*radix`\u800c`groups=k*radix`\u65f6\uff0c`Conv2d`\u6bcf\u4e00`group`\u8f93\u51fa\u7684\u901a\u9053\u6570\u5c31\u662f\u7b49\u4e8e$c'/k$\uff01\uff01\uff01\n", "\n", "\u6709\u4e86\u6743\u91cd`xs`\u540e\uff0c\u53ea\u9700\u8981\u5c06`xs`\u4e58\u4e0a\u76f8\u540cshape\u7684`x`\u518d\u52a0\u4e0a`x`\u5c31\u5f97\u5230\u4e86Split-Attention\u7684\u8f93\u51fa\uff08\u6ce8\u610f\u8fd9\u91cc\u7701\u7565\u4e861x1\u7f29\u5c0f\u548c\u653e\u5927\u901a\u9053\u7684\u6b65\u9aa4\uff09\u3002\u8fd9\u91cc\u6709\u8bc1\u660e\u4e24\u8005\u7b49\u4ef7\u8bc1\u660e\u548c\u8bba\u6587\u4f5c\u8005\u6d4b\u8bd5\u4ee3\u7801\uff08\u8f7d\u5165\u7b49\u4ef7\u7684\u7f51\u7edc\u6743\u91cd\uff0c\u63d0\u4f9b\u76f8\u540c\u7684\u8f93\u5165\uff0c\u901a\u8fc7\u6d4b\u8bd5\u8f93\u51fa\u662f\u5426\u76f8\u540c\u6765\u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u7b49\u4ef7\uff09\uff0c\u8be6\u89c1[ResNeSt \u5b9e\u73b0\u6709\u8bef\uff1f](https://zhuanlan.zhihu.com/p/135220104)\u3002\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/8hjis3n8sybi782qv7g2fks1/image.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u6ce8\u610f\u56fe\u4e2d\u4f7f\u7528\u7684\u662f**r-Softmax**\uff0c\u5f53`radix=1`\u65f6\u7528`sigmoid`\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a\n", "\n", "$$a_{i}^{k}(c)=\\left\\{\\begin{array}{ll}\n", "\\frac{\\exp \\left(\\mathcal{G}_{i}^{c}\\left(s^{k}\\right)\\right)}{\\sum_{j=0}^{R} \\exp \\left(\\mathcal{G}_{j}^{c}\\left(s^{k}\\right)\\right)} & \\text { if } R>1 \\\\\n", "\\frac{1}{1+\\exp \\left(-\\mathcal{G}_{i}^{c}\\left(s^{k}\\right)\\right)} & \\text { if } R=1\n", "\\end{array}\\right.$$\n", "\n", "\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff0c\u6ce8\u610f`x.transpose`\u64cd\u4f5c\u8c03\u6362\u4e86radix\u548ccardinality\u7ef4\u5ea6\uff1a"]}, {"cell_type": "code", "execution_count": 18, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.342229Z", "start_time": "2020-08-11T08:05:57.277634Z"}}, "outputs": [], "source": ["class rSoftMax(nn.Module):\n", "    def __init__(self, radix, cardinality):\n", "        super().__init__()\n", "        self.radix = radix\n", "        self.cardinality = cardinality\n", "\n", "    def forward(self, x):\n", "        batch = x.size(0)\n", "        if self.radix > 1:\n", "            x = x.view(batch, self.cardinality, self.radix, -1)\n", "            x = x.transpose(1, 2)  # batch, radix, cardinality, -1\n", "            x = F.softmax(x, dim=1)\n", "            x = x.reshape(batch, -1)\n", "        else:\n", "            x = torch.sigmoid(x)\n", "        return x"]}, {"cell_type": "code", "execution_count": 19, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.374615Z", "start_time": "2020-08-11T08:05:57.345497Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([1, 128])\n"]}], "source": ["radix = 2\n", "cardinality = 4\n", "c = 16\n", "x = torch.rand(1, radix*cardinality, c)\n", "out = rSoftMax(radix, cardinality)(x)\n", "\n", "print('out shape : {}'.format(out.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u589e\u52a0\u4e86Split-Attention\u7684ResNet\u6a21\u5757\u4ee3\u7801\uff0c\u6ce8\u610f\u4ee3\u7801\u4e2d**\u75281x1\u7684Conv\u4ee3\u66ff\u4e86cardinality\\*radix\u4e2a\u5e76\u884cFC\u7684\u9884\u7b97**\uff1a"]}, {"cell_type": "code", "execution_count": 20, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.442439Z", "start_time": "2020-08-11T08:05:57.378146Z"}}, "outputs": [], "source": ["class SplAtConv2d(nn.Module):\n", "    \"\"\"Split-Attention Conv2d\n", "    \"\"\"\n", "\n", "    def __init__(self, in_channels, channels, kernel_size=3, stride=1,\n", "                 padding=1, dilation=1, groups=1, bias=False,\n", "                 radix=2, reduction_factor=4, **kwargs):\n", "        super(SplAtConv2d, self).__init__()\n", "        inter_channels = max(in_channels*radix//reduction_factor, 32)\n", "        self.radix = radix\n", "        self.cardinality = groups\n", "        self.channels = channels\n", "\n", "        self.conv = nn.Conv2d(in_channels, channels*radix, kernel_size, stride,\n", "                              padding, dilation, groups=groups*radix, bias=bias, **kwargs)\n", "        self.bn0 = nn.BatchNorm2d(channels*radix)\n", "        self.relu = nn.ReLU(inplace=True)\n", "\n", "        self.fc1 = nn.Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n", "        self.bn1 = nn.BatchNorm2d(inter_channels)\n", "        self.fc2 = nn.Conv2d(inter_channels, channels *\n", "                             radix, 1, groups=self.cardinality)\n", "        self.rsoftmax = rSoftMax(radix, groups)\n", "\n", "    def forward(self, x):\n", "        x = self.conv(x)\n", "        x = self.bn0(x)\n", "        x = self.relu(x)\n", "\n", "        batch, rchannel = x.shape[:2]\n", "        if self.radix > 1:\n", "            splited = torch.split(x, rchannel//self.radix, dim=1)\n", "            gap = sum(splited)\n", "        else:\n", "            gap = x\n", "        gap = F.adaptive_avg_pool2d(gap, 1)\n", "        gap = self.fc1(gap)\n", "\n", "        gap = self.bn1(gap)\n", "        gap = self.relu(gap)\n", "\n", "        atten = self.fc2(gap)\n", "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n", "\n", "        if self.radix > 1:\n", "            attens = torch.split(atten, rchannel//self.radix, dim=1)\n", "            out = sum([att*split for (att, split) in zip(attens, splited)])\n", "        else:\n", "            out = atten * x\n", "        return out.contiguous()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u56e0\u4e3a\u4ee3\u7801\u4e2d\u5bf9FC\u8f93\u51fa\u7528\u4e86BatchNorm\uff0c\u6240\u4ee5\u6d4b\u8bd5\u65f6\u5019batch size > 1\uff1a"]}, {"cell_type": "code", "execution_count": 21, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.476599Z", "start_time": "2020-08-11T08:05:57.444713Z"}, "scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([2, 32, 56, 56])\n"]}], "source": ["x = torch.rand(2, 64, 56, 56)\n", "out = SplAtConv2d(64, 32)(x)\n", "print('out shape : {}'.format(out.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 3.4.1 Tricks\n", "\u672c\u7bc7\u8bba\u6587\u8bad\u7ec3\u65f6\u7528\u5230\u4e86\u5f88\u591atricks\u3002\u9996\u5148ResNet-D\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/scdvz53jz5elyfjsgdwugxco/image.png)\n", "1. ResNet-B\u5c06`s=2`\u4e0b\u91c7\u6837\uff08downsampling\uff09\u4ece\u7b2c\u4e00\u4e2a\uff08\u6700\u4e0b\u9762\uff091x1\u79fb\u5230\u4e863x3\u5377\u79ef\u4e2d\uff0c\u907f\u514d\u4fe1\u606f\u4e22\u5931\uff08\u56e0\u4e3a`s=2`\u76841x1\u4f1a\u76f4\u63a5\u8df3\u8fc7\u50cf\u7d20\uff09\u3002\n", "2. ResNet-C\u4e2d\u5c06ResNet\u7b2c\u4e00\u5c42\u76847x7\u5377\u79ef\u75283\u4e2a3x3\u5377\u79ef\u4ee3\u66ff\u3002\n", "3. ResNet-D\u4e2d\u89e3\u51b3\u4e86ResNet-B\u4e2d\u65c1\u8def\u4e0a1x1\u5728`s=2`\u65f6\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\uff0c\u5148\u7528`AvgPool`\u8fdb\u884c\u4e0b\u91c7\u6837\u3002\n", "\n", "\u5176\u4ed6\u8fd8\u6709Label Smoothing\uff0cMixup Training\uff0cAuto Augment\u7b49\u3002\u4f5c\u8005\u5b9e\u73b0\u7684[\u4ee3\u7801](https://github.com/zhanghang1989/ResNeSt)\u63d0\u4f9b\u4e86MXNet\u548cPyTorch\u7248\u672c\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4 CV Attention\n", "\n", "\u6ce8\u610f\u529b\u673a\u5236\u53ef\u4ee5\u5206\u4e3a\uff1a\n", "- \u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\uff1a\u5bf9\u901a\u9053\u751f\u6210\u63a9\u7801mask\uff0c\u8fdb\u884c\u6253\u5206\uff0c\u4ee3\u8868\u662fSENet, Channel Attention Module\n", "- \u7a7a\u95f4\u6ce8\u610f\u529b\u673a\u5236\uff1a\u5bf9\u7a7a\u95f4\u8fdb\u884c\u63a9\u7801\u7684\u751f\u6210\uff0c\u8fdb\u884c\u6253\u5206\uff0c\u4ee3\u8868\u662fSpatial Attention Module\n", "- \u6df7\u5408\u57df\u6ce8\u610f\u529b\u673a\u5236\uff1a\u540c\u65f6\u5bf9\u901a\u9053\u6ce8\u610f\u529b\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u8fdb\u884c\u8bc4\u4ef7\u6253\u5206\uff0c\u4ee3\u8868\u7684\u6709BAM, CBAM\n", "\n", "\u6587\u7ae0\uff1a\n", "- \u4e13\u680f\uff1a[\u673a\u5668\u89c6\u89c9Attention\u673a\u5236\u7684\u7814\u7a76](https://zhuanlan.zhihu.com/cvattention)\n", "  - [Attention\u7b97\u6cd5\u8c03\u7814\u2014\u2014\u89c6\u89c9\u5e94\u7528\u6982\u51b5](https://zhuanlan.zhihu.com/p/52925608)\n", "  - [Attention\u7b97\u6cd5\u8c03\u7814(\u4e00)\u2014\u2014\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684Attention](https://zhuanlan.zhihu.com/p/52786464)\n", "  - [Attention\u7b97\u6cd5\u8c03\u7814(\u4e8c)\u2014\u2014\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684Self Attention](https://zhuanlan.zhihu.com/p/52861193)\n", "  - [Attention\u7b97\u6cd5\u8c03\u7814(\u4e09)\u2014\u2014\u89c6\u89c9\u5e94\u7528\u4e2d\u7684Hard Attention](https://zhuanlan.zhihu.com/p/52958865)\n", "  - [Attention\u7b97\u6cd5\u8c03\u7814(\u56db)\u2014\u2014\u89c6\u89c9\u5e94\u7528\u4e2d\u7684Soft Attention](https://zhuanlan.zhihu.com/p/53026371)\n", "  - [Attention\u7b97\u6cd5\u8c03\u7814(\u4e94)\u2014\u2014\u89c6\u89c9\u5e94\u7528\u4e2d\u7684Self Attention](https://zhuanlan.zhihu.com/p/53155423)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 4.1 CBAM\n", "\u4e3a\u4e86\u5f3a\u8c03\u7a7a\u95f4\u548c\u901a\u9053\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u6709\u610f\u4e49\u7279\u5f81\uff0c\u4f5c\u8005\u4f9d\u6b21\u5e94\u7528\u901a\u9053\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5206\u522b\u5728\u901a\u9053\u548c\u7a7a\u95f4\u7ef4\u5ea6\u4e0a\u5b66\u4e60\u5173\u6ce8\u4ec0\u4e48\u3001\u5728\u54ea\u91cc\u5173\u6ce8\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e86\u89e3\u8981\u5f3a\u8c03\u6216\u6291\u5236\u7684\u4fe1\u606f\u4e5f\u6709\u52a9\u4e8e\u7f51\u7edc\u5185\u7684\u4fe1\u606f\u6d41\u52a8\u3002\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/z8o0mdlygap9p5mkkgpbkcae/image.png)\n", "\n", "\u4e3b\u8981\u7f51\u7edc\u67b6\u6784\u4e5f\u5f88\u7b80\u5355\uff0c\u4e0a\u56fe\u5c55\u793a\u4e86\u548cResBlock\u7684\u7ed3\u5408\uff0c\u5bf9Feature Maps\u4f9d\u6b21\u901a\u8fc7Channel attention\u548cSpatial attention\u4e24\u4e2amodule\u3002\u539f\u6587\uff1a   Given an intermediate feature map $\\mathbf{F} \\in \\mathbb{R}^{C \\times H \\times W}$ as input, CBAM sequentially infers a 1D channel attention map $\\mathbf{M}_{\\mathbf{c}} \\in \\mathbb{R}^{C \\times 1 \\times 1}$ and a 2D spatial attention map $\\mathbf{M}_{\\mathbf{s}} \\in \\mathbb{R}^{1 \\times H \\times W}$:\n", "\n", "$$\\begin{aligned}\n", "\\mathbf{F}^{\\prime} &=\\mathbf{M}_{\\mathbf{c}}(\\mathbf{F}) \\otimes \\mathbf{F} \\\\\n", "\\mathbf{F}^{\\prime \\prime} &=\\mathbf{M}_{\\mathbf{s}}\\left(\\mathbf{F}^{\\prime}\\right) \\otimes \\mathbf{F}^{\\prime}\n", "\\end{aligned}$$\n", "\n", "\u5176\u4e2d$\\otimes$\u8868\u793aelement-wise multiplication\u3002\u4e24\u4e2a\u6a21\u5757\u8be6\u7ec6\u7684\u7ed3\u6784\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n", "\n", "![](http://static.zybuluo.com/AustinMxnet/gkkkb0jf3q352fr8mdwgjgda/image.png)\n", "\n", "\u81f3\u4e8e\u4e3a\u4ec0\u4e48Channel\u5728\u524d\uff0cSpatial\u5728\u540e\uff0c\u662f\u56e0\u4e3a\u5b9e\u9a8c\u7ed3\u679c\u66f4\u597d\u3002\u4e0b\u9762\u5206\u522b\u770b\u4e0b\u4e24\u4e2a\u6a21\u5757\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Channel attention module**\u7684\u516c\u5f0f\u5982\u4e0b\uff1a\n", "\n", "$$\\begin{aligned}\n", "\\mathbf{M}_{\\mathbf{c}}(\\mathbf{F}) &=\\sigma(\\textit{MLP}(\\textit{AvgPool}(\\mathbf{F}))+\\textit{MLP}(\\textit{MaxPool}(\\mathbf{F}))) \\\\\n", "&=\\sigma\\left(\\mathbf{W}_{1}\\left(\\mathbf{W}_{\\mathbf{0}}\\left(\\mathbf{F}_{\\text{avg}}^{\\mathbf{c}}\\right)\\right)+\\mathbf{W}_{\\mathbf{1}}\\left(\\mathbf{W}_{\\mathbf{0}}\\left(\\mathbf{F}_{\\text{max}}^{\\mathbf{c}}\\right)\\right)\\right)\n", "\\end{aligned}$$\n", "\n", "\u5176\u4e2d\uff1a\n", "- $\\mathbf{F}_{\\text{avg}}^{\\mathbf{c}}$\u548c$\\mathbf{F}_{\\text{max}}^{\\mathbf{c}}$\u5206\u522b\u8868\u793a\u5728\u7a7a\u95f4$HW$\u7ef4\u5ea6\u4e0aaverage-pooled\u548cmax-pooled features\uff0c\u5927\u5c0f\u4e3a\u901a\u9053\u6570$c$\u3002\u4f5c\u8005\u8ba4\u4e3a\u7ed3\u5408max-pooling\u548caverage-pooling\u80fd\u63d0\u4f9b\u66f4\u591a\u7684\u4fe1\u606f\u3002\n", "\n", "- $\\mathbf{W}_{\\mathbf{0}}, \\mathbf{W}_{\\mathbf{1}} \\in \\mathbb{R}^{C / r \\times C}$\uff0c$r$\u662freduction ratio\uff0c\u51cf\u5c11\u8ba1\u7b97\u91cf\u7684\u3002**\u6ce8\u610f\u8fd9\u4e24\u4e2aweight\u53c2\u6570\u662f\u88ab$\\textit{MLP}$\u5171\u4eab\u7684**\uff0c\u6240\u4ee5\u4e0b\u9762\u7684\u4ee3\u7801\u4f7f\u7528\u4e86\u4e00\u4e2a`sharedMLP`\u3002\n", "\n", "- $\\sigma$\u8868\u793asigmod\u51fd\u6570\u3002\n", "\n", "- $M_c\\in \\mathbb{R}^{C\\times 1 \\times 1}$\u5c31\u662fchannel attention map\u3002"]}, {"cell_type": "code", "execution_count": 22, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.497112Z", "start_time": "2020-08-11T08:05:57.489259Z"}}, "outputs": [], "source": ["class ChannelAttention(nn.Module):\n", "    def __init__(self, in_planes, ratio=16):\n", "        super(ChannelAttention, self).__init__()\n", "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n", "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n", "\n", "        self.sharedMLP = nn.Sequential(\n", "            nn.Conv2d(in_planes, in_planes//ratio, 1, bias=False),\n", "            nn.ReLU(),\n", "            nn.Conv2d(in_planes//ratio, in_planes, 1, bias=False)\n", "        )\n", "        self.sigmoid = nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        avg_out = self.sharedMLP(self.avg_pool(x))\n", "        max_out = self.sharedMLP(self.max_pool(x))\n", "        out = avg_out + max_out\n", "        return self.sigmoid(out)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\mathbf{F}^{\\prime} =\\mathbf{M}_{\\mathbf{c}}(\\mathbf{F}) \\otimes \\mathbf{F}$"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.527966Z", "start_time": "2020-08-11T08:05:57.508617Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Mc shape : torch.Size([1, 128, 1, 1])\n", "xc shape : torch.Size([1, 128, 14, 14])\n"]}], "source": ["x = torch.rand(1, 128, 14, 14)\n", "# channel attention map\n", "Mc = ChannelAttention(128)(x)\n", "\n", "print('Mc shape : {}'.format(Mc.shape))\n", "\n", "# features with channel attention\n", "xc = x * Mc \n", "print('xc shape : {}'.format(xc.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Spatial attention module**\u7684\u516c\u5f0f\u5982\u4e0b\uff1a\n", "\n", "$$\\begin{aligned}\n", "\\mathbf{M}_{\\mathbf{s}}(\\mathbf{F}) &=\\sigma\\left(f^{7 \\times 7}([\\textit{AvgPoll}(\\mathbf{F}) ; \\textit{MaxPool}(\\mathbf{F})])\\right) \\\\\n", "&=\\sigma\\left(f^{7 \\times 7}\\left(\\left[\\mathbf{F}_{\\text{avg}}^{\\mathbf{s}} ; \\mathbf{F}_{\\text{max}}^{\\mathbf{s}}\\right]\\right)\\right)\n", "\\end{aligned}$$\n", "\n", "\u5176\u4e2d\uff1a\n", "- $\\mathbf{F}_{\\text{avg}}^{\\mathbf{s}}, \\mathbf{F}_{\\text{max}}^{\\mathbf{s}} \\in \\mathbb{R}^{1 \\times H \\times W}$\uff0c\u5206\u522b\u8868\u793a\u5728\u901a\u9053$c$\u7ef4\u5ea6\u4e0aaverage-pooled\u548cmax-pooled features\uff0c\u7136\u540e\u628a\u8fd9\u4e24\u4e2a2D features\u88abconcatenate\u5728\u4e00\u8d77\u3002\n", "\n", "- $f^{7 \\times 7}$\u8868\u793afilter size\u4e3a$7\\times7$\u7684\u5377\u79ef\u3002\n", "\n", "- $\\sigma$\u8868\u793asigmod\u51fd\u6570\u3002\n", "\n", "- $M_s\\in \\mathbb{R}^{H\\times W}$\u5c31\u662fspatial attention map\u3002"]}, {"cell_type": "code", "execution_count": 24, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.543160Z", "start_time": "2020-08-11T08:05:57.530477Z"}}, "outputs": [], "source": ["class SpatialAttention(nn.Module):\n", "    def __init__(self, kernel_size=7):\n", "        super(SpatialAttention, self).__init__()\n", "        assert kernel_size in (3, 7), \"kernel size must be 3 or 7\"\n", "        padding = 3 if kernel_size == 7 else 1\n", "\n", "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n", "        self.sigmoid = nn.Sigmoid()\n", "\n", "    def forward(self, x):\n", "        avg_out = torch.mean(x, dim=1, keepdim=True)\n", "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n", "        x = torch.cat([avg_out, max_out], dim=1)\n", "        x = self.conv(x)\n", "        return self.sigmoid(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$\\mathbf{F}^{\\prime \\prime} =\\mathbf{M}_{\\mathbf{s}}\\left(\\mathbf{F}^{\\prime}\\right) \\otimes \\mathbf{F}^{\\prime}$"]}, {"cell_type": "code", "execution_count": 25, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.573508Z", "start_time": "2020-08-11T08:05:57.546156Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Ms shape : torch.Size([1, 1, 14, 14])\n", "xc shape : torch.Size([1, 128, 14, 14])\n"]}], "source": ["x = torch.rand(1, 128, 14, 14)\n", "# channel attention map\n", "Ms = SpatialAttention()(x)\n", "\n", "print('Ms shape : {}'.format(Ms.shape))\n", "\n", "# features with channel attention\n", "xs = x * Ms \n", "print('xc shape : {}'.format(xs.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u628a\u4e24\u8005\u7ed3\u5408\u8d77\u6765\u5c31\u5f97\u5230\u4e86`CBAM`\u6a21\u5757\uff1a"]}, {"cell_type": "code", "execution_count": 26, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.582027Z", "start_time": "2020-08-11T08:05:57.575839Z"}}, "outputs": [], "source": ["class CBAM(nn.Module):\n", "    def __init__(self, planes):\n", "        super().__init__()\n", "        self.ca = ChannelAttention(planes)\n", "        self.sa = SpatialAttention()\n", "\n", "    def forward(self, x):\n", "        x = self.ca(x) * x\n", "        x = self.sa(x) * x\n", "        return x"]}, {"cell_type": "code", "execution_count": 27, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.610859Z", "start_time": "2020-08-11T08:05:57.589053Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["out shape : torch.Size([1, 128, 14, 14])\n"]}], "source": ["x = torch.rand(1, 128, 14, 14)\n", "\n", "out = CBAM(128)(x)\n", "print('out shape : {}'.format(out.shape))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u539f\u6587\u4e2d\u628a`CBAM`\u548c`ResNet`\u96c6\u6210\u65f6\u662f\u8fd9\u4e48\u8bf4\u7684\uff1a\u201cWe apply CBAM on the convolution outputs in each block\u201d\uff0c\u53ef\u80fd\u662f\u52a0\u5728\u6bcf\u4e2a`ResBlock`\u8f93\u51fa\u4e0a\uff08\u672a\u9a8c\u8bc1\uff09\u3002\u5728\u8fd9\u7bc7[\u6587\u7ae0](https://zhuanlan.zhihu.com/p/99261200)\u4e2d\uff0c**\u4f5c\u8005\u4e3a\u4e86\u80fd\u591f\u7528\u9884\u8bad\u7ec3\u7684\u53c2\u6570**\uff0c\u628a`CBAM`\u52a0\u5728`ResBlock`\u4e4b\u524d\u548c\u4e4b\u540e\uff0c\u89c1`ca/sa`\u548c`ca1/sa1`\uff1a"]}, {"cell_type": "code", "execution_count": 28, "metadata": {"ExecuteTime": {"end_time": "2020-08-11T08:05:57.727336Z", "start_time": "2020-08-11T08:05:57.613642Z"}}, "outputs": [], "source": ["%%script true\n", "class ResNet(nn.Module):\n", "    x = self.conv1(x)\n", "\n", "    x = self.ca(x) * x\n", "    x = self.sa(x) * x\n", "\n", "    x = self.maxpool(x)\n", "\n", "    x = self.layer1(x)\n", "    x = self.layer2(x)\n", "    x = self.layer3(x)\n", "    x = self.layer4(x)\n", "\n", "    x = self.ca1(x) * x\n", "    x = self.sa1(x) * x\n", "\n", "    x = self.avgpool(x)\n", "    x = x.reshape(x.size(0), -1)\n", "    x = self.fc(x)"]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "notebook_metadata_filter": "-all"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.10"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "calc(100% - 180px)", "left": "10px", "top": "150px", "width": "230px"}, "toc_section_display": true, "toc_window_display": true}}, "nbformat": 4, "nbformat_minor": 4}